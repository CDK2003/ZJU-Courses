---
title: "回归分析大作业"
author: "柴大开 3210103517"
CJKmainfont: SimSun
output:
  pdf_document:
    includes:
      header-includes:
        keep_tex: true
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE)
```

# **实验问题**
  本案例收集了1990-2020年的**国内生产总值x1、出口量x2、总消费量x3**以及**总进口量y**的数据（单位均为亿元），希望通过x1,x2,x3的历年数据去预测y的数据。以下为1990-2020年的相关数据：

```{r 1}
 read.table("F:/Desktop/大学学习/专业课程/选修/回归分析/大作业/相关数据.txt")
```
  以上的数据从左到右分别为国内生产总值(V1)、出口量(V2)、总消费量(V3)以及总进口量(V4).（数据来源于《中国统计年鉴-2022年》。）    

# **数据处理**

  首先获得各变量的**样本均值、样本标准差**数据，代码如下：

```{r 2}
 yx=read.table("F:/Desktop/相关数据.txt")
 x1=yx[,1]
 x2=yx[,2]
 x3=yx[,3]
 y=yx[,4]
 mean(x1);mean(x2);mean(x3);mean(y)
 sd(x1);sd(x2);sd(x3);sd(y)
```

# **实验步骤**

  本实验主要通过最小二乘法、多重共线性诊断、岭估计法与主成分估计法来进行数据分析。

### **1、最小二乘法**

  首先使用**最小二乘法**进行分析，结果如下：

```{r 3}
 economy=data.frame(y,x1,x2,x3)
 lm.sol=lm(y~.,data=economy)
 summary(lm.sol)
```

  得到回归方程：
$$\large\hat{y}=2427.82757+0.15528x_1+1.75391x_2-0.26641x_3$$  
  根据回归方程，$x_1$和$x_2$前的回归系数都是正的，而$x_3$的回归系数为负。这与经济意义不符合（全国总消费量与总进口量理论上来讲是成正相关），所以说回归系数的符号与实际不符。  

### **2、多重共线性诊断**

  接下来从**多重共线性**的角度考虑自变量之间的关系，考察样本的相关系数矩阵：
```{r 4}
 X=cbind(x1,x2,x3)
 rho=cor(X)
 rho
```
  从数据中可以看出$x_1,x_2,x_3$三者之间均互相存在着高度的线性相关性。

  那么接下来进行**多重共线性诊断**：

```{r 5}
 library(DAAG)
 vif(lm.sol)
 eigen(rho)
 kappa(rho,exact = TRUE)
```

### **3、岭估计法**

  接下来用**岭估计方法**寻找**岭回归方程**。  

  首先对数据进行标准化，代码如下：
```{r 6}
 yxs=scale(yx)
 x1=yxs[,1]
 x2=yxs[,2]
 x3=yxs[,3]
 y=yxs[,4]
 economy2=data.frame(x1,x2,x3,y)
```

  然后进行岭估计：

```{r 7}
 library(MASS)
 rr.sol=lm.ridge(y~0+x1+x2+x3,data=economy2,lambda=seq(0,1,by=0.05))
 rr.sol
```

  画出**岭迹图**：

```{r 8}
 matplot(rr.sol$lambda,t(rr.sol$coef),type="l",col=c("red","blue","black"),xlab=expression(lambda),ylab=expression(hat(beta)(lambda)))
```

  根据岭迹图选择**岭参数**$k=0.85$,得到标准化变量的岭回归方程为：
$$\large\hat{v}=0.1637u_1+0.7892u_2+0.0317u_3$$
  转换成原始变量的岭回归方程：
$$\frac{\hat{y}-133990}{111078.6}=0.1637\times\frac{x_1-334824.7}{319151.4}+0.7892\times\frac{x_2-72883.17}{61019.01}+0.0317\times\frac{x_3-181146.5}{173127.5}$$
  即得到
$$\large\hat{y}=6517.799+0.057x_1+1.437x_2+0.020x_3$$
  由于本案例中各个变量的量纲一致（均为亿元），故可以直接对原始数据进行岭估计：
```{r 9}
 rr.sol=lm.ridge(y~.,data=economy,lambda=seq(0,1,by=0.05))
 rr.sol
 plot(rr.sol)
```

  同样根据岭迹图选择岭参数$k=0.85$,得到岭回归方程：
$$\large\hat{y}=6517.799+0.057x_1+1.437x_2+0.020x_3$$
  与上面的结果一致！  

  上面已经完成了**最小二乘估计**与**多重共线性诊断**。 

### **4、主成分估计法**

  为了消除多重共线性的影响，接下来我们进行主成分估计：

```{r 10}
 economy.pr=princomp(~x1+x2+x3,data=economy,cor=TRUE)
 summary(economy.pr,loadings=TRUE)
```

  第三个特征根 $\lambda_3=0.0207824374^2=0.0004319\approx 0$  

  对应三个**标准正交化特征向量**为：
$$\phi_1=(0.581,0.296,0.758)'$$
$$\phi_2=(0.572,-0.811,-0.122)'$$
$$\phi_3=(0.579,0.504,-0.641)'$$
  三个主成分分别为：
$$z_1=0.581x_1^*+0.296x_2^*+0.758x_3^*$$
$$z_2=0.572x_1^*-0.811x_2^*-0.122x_3^*$$
$$z_3=0.579x_1^*+0.504x_2^*-0.641x_3^*$$
  因为第一个特征根的累计贡献率为 $0.9812802\ge0.85$，所以删去后两个主成分，只保留第一个主成分。  

  计算主成分得分（即主成分的观测向量）：

```{r 11}
 pre=predict(economy.pr)
 pre
```

  进行主成分估计：

```{r 12}
 z1=pre[,1]
 yxs=scale(yx)
 u=yxs[,4]
 economynew=data.frame(u,z1)
 pc.sol=lm(u~0+z1,data=economynew)
 summary(pc.sol)
```

  得到**主成分回归方程**：
$\large\hat{u}=0.56097z_1$  

$\large=0.56097(0.581x_1^*+0.296x_2^*+0.758x_3^*)$  

$\large=0.325924x_1^*+0.166047x_2^*+0.425215x_3^*$

  转化为原始变量的回归方程，得到：
$$\frac{\hat{y}-133990}{111078.6}=0.325924\times\frac{x_1-334824.7}{319151.4}+0.166047\times\frac{x_2-72883.17}{61019.01}+0.425215\times\frac{x_3-181146.5}{173127.5}$$
  即
$$\large\hat{y}=24558.434+0.113x_1+0.302x_2+0.273x_3$$
  这里的$y,x_1,x_2,x_3$表示原始变量。

# **实验结论与心得**
  由以上的结果可以看出，最小二乘法、岭估计法与主成分估计法得到的三个回归方程之间仍然存在着不小的差距。主要的原因就是选取的自变量与因变量之间的时候没有考虑到变量选取的合理性。这提醒了我将来在分析数据时，对于自变量的选择要更加注意（首先进行自变量的合理选取与模型的诊断）。但是其中，与最小而成估计相比，岭估计和主成分估计都一定程度上缓解了多重共线性带来的影响，因此$x_3$的回归系数的点估计的符号也发生了变化。  
  通过这次案例分析，我更加熟练了r语言的基本操作，并且能将其应用于经济生活方面相关的问题，感觉还是很有意义的。在庞老师上课讲解相关代码的基础上，加上自己动手操作，才能更加熟练r语言的使用。毕竟对于统计方向来说，r语言无疑是一个很重要的软件。除此之外，这次实验让我对多重共线性、岭估计方法和主成分估计等知识有了更加深刻的了解。回归分析是一门很强大的学科，还有很多理论知识和方法需要我继续学习和掌握，这对于将来更好地分析和解释经济生活方面的现象具有重要意义。